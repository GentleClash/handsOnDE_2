services:
  broker_1:
    image: apache/kafka:latest
    container_name: broker_1
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@broker_1:29093
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,CONTROLLER://0.0.0.0:29093,EXTERNAL://0.0.0.0:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker_1:29092,EXTERNAL://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 3
    healthcheck:
      test: ["CMD", "/opt/kafka/bin/kafka-broker-api-versions.sh", "--bootstrap-server", "localhost:29092"]
      interval: 5s
      timeout: 10s
      retries: 5
      start_period: 10s

  broker_2:
    image: apache/kafka:latest
    container_name: broker_2
    ports:
      - "9093:9092"
    environment:
      KAFKA_NODE_ID: 2
      KAFKA_PROCESS_ROLES: broker
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@broker_1:29093
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,EXTERNAL://0.0.0.0:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker_2:29092,EXTERNAL://localhost:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 3
    healthcheck:
      test: ["CMD", "/opt/kafka/bin/kafka-broker-api-versions.sh", "--bootstrap-server", "localhost:29092"]
      interval: 5s
      timeout: 10s
      retries: 5
      start_period: 10s


  producer:
    build:
      context: .
      dockerfile: Dockerfile.app 
    container_name: kafka_producer
    depends_on:
      broker_1:
        condition: service_healthy
      broker_2:
        condition: service_healthy
    environment:
      KAFKA_PRODUCER_BOOTSTRAP_SERVERS: broker_1:29092,broker_2:29092
      SYNTHETIC_DATA_OUTPUT_DIR: /data
    volumes:
      - ./data:/data
    command: ["python", "producer/run_stream.py"]

  consumer_1:
    build:
      context: .
      dockerfile: Dockerfile.app
    container_name: kafka_consumer_1
    depends_on:
      broker_1:
        condition: service_healthy
      broker_2:
        condition: service_healthy
    environment:
      KAFKA_CONSUMER_BOOTSTRAP_SERVERS: broker_1:29092,broker_2:29092
      KAFKA_CONSUMER_GROUP: raw-data-archive
      KAFKA_CONSUMER_TOPICS: orders.events,riders.events
      KAFKA_CONSUMER_AUTO_OFFSET_RESET: earliest
      DATA_LAKE_BASE_DIR: /data_lake/raw
    volumes:
      - ./data_lake:/data_lake
    command: ["python", "consumers/kafka_to_lake.py"]

  consumer_2:
    build:
      context: .
      dockerfile: Dockerfile.app
    container_name: kafka_consumer_2
    depends_on:
      broker_1:
        condition: service_healthy
      broker_2:
        condition: service_healthy
    environment:
      KAFKA_CONSUMER_BOOTSTRAP_SERVERS: broker_1:29092,broker_2:29092
      KAFKA_CONSUMER_GROUP: raw-data-archive
      KAFKA_CONSUMER_TOPICS: orders.events,riders.events
      KAFKA_CONSUMER_AUTO_OFFSET_RESET: earliest
      DATA_LAKE_BASE_DIR: /data_lake/raw
    volumes:
      - ./data_lake:/data_lake
    command: ["python", "consumers/kafka_to_lake.py"]

  
  airflow-db:
    image: postgres:17.7-alpine
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s
    volumes:
      - airflow-db-volume:/var/lib/postgresql/data
  
  airflow-init:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow_init
    depends_on:
      airflow-db:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-db:5432/airflow
      - _AIRFLOW_DB_MIGRATE=true
      - _AIRFLOW_WWW_USER_CREATE=true
      - _AIRFLOW_WWW_USER_USERNAME=admin
      - _AIRFLOW_WWW_USER_PASSWORD=admin
    command: version
  
  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    #cgroups: host
    container_name: airflow_webserver
    restart: always
    depends_on:
      airflow-db:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    ports:
      - "8080:8080"
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-db:5432/airflow
      - AIRFLOW__LOAD_EXAMPLES=False
    volumes:
      - ./logs:/opt/airflow/logs
      - ./dags:/opt/airflow/dags
    #deploy:
    #  resources:
    #    limits:
    #      memory: 2G
    command: api-server
  
  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    #cgroups: host
    container_name: airflow_scheduler
    restart: always
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-db:5432/airflow
      - AIRFLOW__DAG_PROCESSOR__REFRESH_INTERVAL=10
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - KAFKA_BOOTSTRAP_SERVERS=broker_1:29092,broker_2:29092
    volumes:
      - ./logs:/opt/airflow/logs
      - ./dags:/opt/airflow/dags
    #deploy:
    #  resources:
    #    limits:
    #      memory: 2G
    command: scheduler

volumes:
  airflow-db-volume:
